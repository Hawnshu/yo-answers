{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical 1 -  Wordcloud --------------------\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import wikipedia as wp\n",
    "result = wp.page(\"Computer Science\")\n",
    "final_result = result.content\n",
    "def plot_wordcloud(wc):\n",
    "    plt.axis(\"off\")\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(wc)\n",
    "wc = WordCloud(width = 1000, height = 1000, background_color = \"cyan\", random_state = 10, stopwords = STOPWORDS).generate(final_result)\n",
    "plot_wordcloud(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical 2 - Web Scrapping --------------------------\n",
    "# HTML scrapping\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Asian_countries_by_area\"\n",
    "page = urlopen(url)\n",
    "html_page = page.read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "table = soup.find(\"table\", {\"class\":\"wikitable sortable\"})\n",
    "SrNo=[]\n",
    "Country=[]\n",
    "Area=[]\n",
    "rows=table.find(\"tbody\").find_all(\"tr\")\n",
    "for row in rows:\n",
    "    cells=row.find_all(\"td\")\n",
    "    if(cells):\n",
    "        SrNo.append(cells[0].get_text().strip(\"\\n\"))\n",
    "        Country.append(cells[1].get_text().strip(\"\\n\").strip(\"*\"))\n",
    "        Area.append(cells[2].get_text().strip(\"\\n\"))\n",
    "df=pd.DataFrame()\n",
    "df[\"ID\"]=SrNo\n",
    "df[\"Country\"]=Country\n",
    "df[\"Area\"]=Area\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON scrapping\n",
    "\n",
    "import pandas as pd\n",
    "import urllib, json\n",
    "\n",
    "url = \"https://jsonplaceholder.typicode.com/users\" \n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "df = pd.DataFrame(data)\n",
    "df.drop(['address', 'website', 'company'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical 3 - EDA of Titanic Dataset ------------------------\n",
    "import pandas as pd\n",
    "titanic = pd.read_csv(\"train.csv\")\n",
    "titanic.head()\n",
    "titanic.info()\n",
    "titanic.describe()\n",
    "titanic.isnull().sum()\n",
    "titanic_cleaned = titanic.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], axis=1)\n",
    "titanic_cleaned.info()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.catplot(x=\"Sex\", hue=\"Survived\", kind=\"count\", data=titanic_cleaned)\n",
    "\n",
    "titanic_cleaned.groupby(['Sex', 'Survived'])['Survived'].count()\n",
    "group1=titanic_cleaned.groupby(['Sex','Survived'])\n",
    "gender_survived=group1.size().unstack()\n",
    "gender_survived\n",
    "\n",
    "sns.heatmap(gender_survived,annot=True,fmt=\"d\")\n",
    "\n",
    "sns.violinplot(x=\"Sex\",y=\"Age\",hue=\"Survived\",data=titanic_cleaned,split=True)\n",
    "\n",
    "print(\"Oldest Person on the Board:\",titanic_cleaned['Age'].max())\n",
    "print(\"Youngest Person on the Board:\",titanic_cleaned['Age'].min())\n",
    "print(\"Average age Person on the Board:\",titanic_cleaned['Age'].mean())\n",
    "titanic_cleaned.isnull().sum()\n",
    "\n",
    "def impute(cols):\n",
    "    Age=cols[0]\n",
    "    Pclass=cols[1]\n",
    "    if pd.isnull(Age):\n",
    "        if Pclass==1:\n",
    "            return 38\n",
    "        elif Pclass==2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 24\n",
    "    else:\n",
    "        return Age\n",
    "titanic_cleaned['Age'] = titanic_cleaned[['Age','Pclass']].apply(impute,axis=1)\n",
    "titanic_cleaned.corr(method='pearson')\n",
    "\n",
    "sns.heatmap(titanic_cleaned.corr(method=\"pearson\"),annot=True,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
